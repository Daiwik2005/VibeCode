
## ğŸ“Œ Project Title
**Intelligent File Monitoring & Semantic Content Orchestration System**

---

## ğŸ§  Description

VibeCode is a Python-based automation system that:

- ğŸ“‚ Monitors file system changes in real-time
- ğŸ§  Processes file content using semantic intelligence
- ğŸ“ Automatically organizes files into structured folders
- ğŸŒ Provides a simple frontend interface using static `index.html`

The system follows a modular backend architecture where `main.py` acts as the controller and coordinates file watching, semantic processing, and folder orchestration.

It is designed to be scalable, clean, and easy to extend.

---

## ğŸ—ï¸ Architecture Diagram 


![Architecture Diagram](architecture.png)

---

## ğŸ› ï¸ Tech Stack

- Backend: Python 3.x
- Frontend: HTML (Static)
- Architecture: Modular Python Design
- File Monitoring: Watchdog
- AI Model Runtime: Ollama

---

## ğŸ“ Project Structure

```
VibeCode/
â”‚â”€â”€ main.py
â”‚â”€â”€ content_processor.py
â”‚â”€â”€ folder_orchestrator.py
â”‚â”€â”€ file_watcher.py
â”‚â”€â”€ semantic_intelligence.py
â”‚â”€â”€ req.txt
â”‚
â”œâ”€â”€ static/
â”‚    â””â”€â”€ index.html
```

---

# âš™ï¸ Full Dependency Installation & Setup Instructions

## 2ï¸âƒ£ Install Python 

Check version:

```bash
python --version
```

Required:
```
Python 3.8 or higher
```

Download from:
https://www.python.org/downloads/

---



## 5ï¸âƒ£ Install All Project Dependencies

Install from req.txt:

```bash
pip install -r req.txt
```

If needed manually (example):

```bash
pip install watchdog
pip install flask
pip install requests
```
### ğŸ”¹ Ollama Installation (Required)

This project uses Ollama to run local LLM models.

1ï¸âƒ£ Install Ollama from:
https://ollama.com/download

- llama3.2
---

# â–¶ï¸ Running the Project

In main.py we should update the root1 and root2 path
```bash
ROOT_IN  = Path(r"C:\Users\Daiwi\OneDrive\Documents\bands\SEFS_-BANDS-\root1")
ROOT_OUT = Path(r"C:\Users\Daiwi\OneDrive\Documents\bands\SEFS_-BANDS-\root2")
```

```bash
python main.py
```

---
# ğŸŒ Accessing Frontend

If backend serves static content:

```
http://localhost:<PORT>
```

Or open manually:

```
static/index.html
```

---

# ğŸ¥ Demo Section (MVP)

Add your demo links below:

- ğŸ”¹ MVP Overview Video: [https://your-demo-link.com](https://drive.google.com/file/d/1d_namX-q9uP4a5Kfi_gZJHFTLJn2tbX4/view?usp=sharing)
-for demonstation purpose root1 and root2 folders have been taken



# ğŸ“¸ Screenshots 



![Home Page](Home_page.png)
![Processing Output](output.png)





